# NorBERT Multitask Classifier ğŸ‡³ğŸ‡´

This project fine-tunes the Norwegian BERT model `NbAiLab/nb-bert-base` to classify **customer service messages** in Norwegian.

It predicts **three labels at once**:
- ğŸ­ Sentiment (negativ, nÃ¸ytral, positiv)
- ğŸ”¥ Priority (lav, normal, hÃ¸y)
- ğŸ“Œ Category (leveringsproblem, feil vare, fakturaspÃ¸rsmÃ¥l, generell henvendelse, reklamasjon)

---

## ğŸ› ï¸ How it works

- Trained on a synthetic dataset generated via LLM prompts (Grok API)
- Multitask architecture with 3 classifier heads
- Input: plain text message  
- Output: structured labels

---

## ğŸ“ Project Structure

- `src/model.py` â€“ BERT with 3 parallel output heads  
- `src/train_all.py` â€“ multitask fine-tuning loop  
- `src/prepare_data.py` â€“ loads and tokenizes `JSONL` format data  
- `src/predict_all.py` â€“ demo script with pre-written inputs  
- `data/` â€“ includes `norbert_synthetic_sample.jsonl` (subset)

---

ğŸ“¦ Model

Weights (norbert-multitask.pt) not included due to size (600MB).
You can train your own using the provided dataset and code.

---

## ğŸš€ Getting Started

```bash
pip install -r requirements.txt

# Prepare data
python src/prepare_data.py

# Train model
python src/train_all.py

# Run prediction demo
python src/predict_all.py
